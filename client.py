import streamlit as st
from streamlit import session_state as ss
from streamlit_lottie import st_lottie_spinner
from streamlit_image_comparison import image_comparison

import numpy as np
import json

from PIL import Image
import cv2

import torch
from torch import nn
import torchvision.models as models
import torchvision.transforms as transforms

import time

import warnings

warnings.filterwarnings('ignore')

# JSON íŒŒì¼ ê²½ë¡œ
file_path = 'asset/loading.json'
# íŒŒì¼ì„ ì—´ê³  JSON ë°ì´í„° ì½ê¸°
with open(file_path, 'r') as file:
    lottie_animation = json.load(file)

#ë ˆì´ì•„ì›ƒ ì„¤ì •
st.set_page_config(
    page_title="ë‹®ì€ ì–¼êµ´ìƒ ì°¾ê¸°",
    page_icon="ğŸ¶",
    layout="wide")

empty1,con0,empty2 = st.columns([0.5,0.5,0.5])
empty1,con1,con2,empty2 = st.columns([0.3,0.5,0.5,0.3])
empyt1,con3,con4,empty2 = st.columns([0.3,0.5,0.5,0.3])
# empyt1,con4,con5,empty2 = st.columns([0.5,0.5,0.5,0.5])
empyt1,con5,empty2 = st.columns([0.4,1.2,0.4])
empyt1,con6,empty2 = st.columns([0.4,1.2,0.4])

#í™”ë©´ìƒíƒœë¥¼ ì˜ë¯¸í•˜ëŠ” ì„¸ì…˜ ìƒíƒœ
if 'upload_file' not in ss: #íŒŒì¼ ì—…ë¡œë“œ í™”ë©´
    ss['upload_file'] = True

if 'process_img' not in ss:#ì´ë¯¸ì§€ ì²˜ë¦¬ í™”ë©´
    ss['process_img'] = False    

if 'show_result' not in ss:#ê²°ê³¼ ì¶œë ¥ í™”ë©´
    ss['show_result'] = False

#ëª¨ë¸ ë¼ë²¨ ì¹´í…Œê³ ë¦¬.
categories = np.array(['ë¹„ê¸€','ë³´ë”ì½œë¦¬','ì—¬ìš°','í˜¸ë‘ì´','ì‚¬ì','ì¥ëª¨ì¢… ê³ ì–‘ì´','ì¹˜íƒ€','ë‹¨ëª¨ì¢… ê³ ì–‘ì´','ë„ë² ë¥´ë§Œ','ë¦¬íŠ¸ë¦¬ë²„','ëŠ‘ëŒ€','ì‹œì¸„'])

animal_text = {
    'ë¹„ê¸€': 'ë°ê³  ì¾Œí™œí•œ ëŠë‚Œ, í° ê·€ì™€ ë§‘ì€ ëˆˆì´ íŠ¹ì§•. í™œë°œí•˜ê³  í˜¸ê¸°ì‹¬ ë§ì€ ì„±ê²©ìœ¼ë¡œ, ì‚¬ëŒë“¤ê³¼ ì‰½ê²Œ ì–´ìš¸ë¦¬ëŠ” ì‚¬ëŒ.',
    'ë³´ë”ì½œë¦¬': 'ì˜ë¦¬í•˜ê³  ì§‘ì¤‘ë ¥ ìˆëŠ” ì¸ìƒ, ë‚ ë µí•œ ëˆˆë§¤ì™€ ë‚ ì¹´ë¡œìš´ ëˆˆë¹›ì´ íŠ¹ì§•. í™œë™ì ì´ë©° ëª©í‘œ ì§€í–¥ì ì¸ ì„±ê²©ì„ ê°€ì§„ ì‚¬ëŒ.',
    'ì—¬ìš°': 'ì˜ë¦¬í•˜ê³  êµí™œí•œ ì´ë¯¸ì§€, ë‚ ì¹´ë¡œìš´ ëˆˆë§¤ì™€ ë¾°ì¡±í•œ ì´ëª©êµ¬ë¹„ê°€ íŠ¹ì§•. ë¯¼ì²©í•˜ê³  ì•¼ë¬´ì§„ ì„±ê²©ì„ ê°€ì§„ ì‚¬ëŒ.',
    'í˜¸ë‘ì´': 'ê°•ë ¬í•˜ê³  ìœ„ì—„ ìˆëŠ” ì¸ìƒ, ë‚ ì¹´ë¡œìš´ ì´ëª©êµ¬ë¹„ê°€ íŠ¹ì§•. ìš©ë§¹í•˜ê³  ê²°ë‹¨ë ¥ ìˆëŠ” ì„±ê²©ì„ ê°€ì§„ ì‚¬ëŒ.',
    'ì‚¬ì': 'ìœ„ì—„ ìˆê³  ê³ ê·€í•œ ëŠë‚Œ, ê°•ë ¬í•œ ëˆˆë¹›ì´ íŠ¹ì§•. ë¦¬ë”ì‹­ê³¼ ìì‹ ê°ì„ ìƒì§•í•˜ëŠ” ì‚¬ëŒ.',
    'ì¥ëª¨ì¢… ê³ ì–‘ì´': 'ìš°ì•„í•˜ê³  ë¶€ë“œëŸ¬ìš´ ì¸ìƒ, í° ëˆˆì´ íŠ¹ì§•. ë…ë¦½ì ì´ê³  ê³ ìƒí•œ ì„±ê²©ì„ ê°€ì§„ ì‚¬ëŒ.',
    'ì¹˜íƒ€': 'ë‚ ë µí•˜ê³  ë¹ ë¥¸ ì´ë¯¸ì§€, ì‘ì€ ì–¼êµ´ì´ íŠ¹ì§•. ë¯¼ì²©í•˜ê³  í™œë™ì ì¸ ì„±ê²©ì„ ê°€ì§„ ì‚¬ëŒ.',
    'ë‹¨ëª¨ì¢… ê³ ì–‘ì´': 'ê¹”ë”í•˜ê³  ë‚ ë µí•œ ì¸ìƒ, ë‚ ì¹´ë¡œìš´ ëˆˆì´ íŠ¹ì§•. ë…ë¦½ì ì´ë©° í˜¸ê¸°ì‹¬ ë§ì€ ì„±ê²©ì„ ê°€ì§„ ì‚¬ëŒ.',
    'ë„ë² ë¥´ë§Œ': 'ê°•ì¸í•˜ê³  ë‚ ì¹´ë¡œìš´ ëŠë‚Œ, ê°•ë ¬í•œ ëˆˆë¹›ì´ íŠ¹ì§•. ìš©ë§¹í•˜ê³  ë³´í˜¸ ë³¸ëŠ¥ì´ ê°•í•œ ì„±ê²©ì„ ê°€ì§„ ì‚¬ëŒ.',
    'ë¦¬íŠ¸ë¦¬ë²„': 'ì¹œê·¼í•˜ê³  ë”°ëœ»í•œ ëŠë‚Œ, ë°ì€ ëˆˆë¹›ì´ íŠ¹ì§•. ì‚¬êµì ì´ê³  ì¶©ì„±ìŠ¤ëŸ¬ìš´ ì„±ê²©ì„ ê°€ì§„ ì‚¬ëŒ.',
    'ëŠ‘ëŒ€': 'ê°•ë ¬í•˜ê³  ì‹ ë¹„ë¡œìš´ ì¸ìƒ, ë‚ ì¹´ë¡œìš´ ì´ëª©êµ¬ë¹„ê°€ íŠ¹ì§•. ììœ ë¡­ê³  ì•¼ì„±ì ì¸ ì„±ê²©ì„ ê°€ì§„ ì‚¬ëŒ.',
    'ì‹œì¸„': 'ê·€ì—½ê³  ì‚¬ë‘ìŠ¤ëŸ¬ìš´ ëŠë‚Œ, ë‘¥ê·¼ ì–¼êµ´ê³¼ í° ëˆˆì´ íŠ¹ì§•. ì• êµ ë§ê³  ì˜¨ìˆœí•œ ì„±ê²©ì„ ê°€ì§„ ì‚¬ëŒ.'
}


st.markdown("""
            <style>
            h2 {
                color: #7340bf;
                justify-content: center;
            }
            </style>
            """, unsafe_allow_html=True
            )

st.markdown("""
            <style>
            h3 {
                color: #7340bf;
                justify-content: center;
            }
            </style>
            """, unsafe_allow_html=True
            )

def get_category_text(category):
    return animal_text[category]

# Grad-CAM í´ë˜ìŠ¤ ì •ì˜
class GradCAM:
    def __init__(self, model, target_layer):
        self.model = model
        self.target_layer = target_layer
        self.gradient = None
        self.activation = None
        self.model.eval()
        self.register_hooks()

    def register_hooks(self):
        def backward_hook(module, grad_input, grad_output):
            self.gradient = grad_output[0]

        def forward_hook(module, input, output):
            self.activation = output

        self.target_layer.register_forward_hook(forward_hook)
        self.target_layer.register_backward_hook(backward_hook)

    def forward(self, x):
        return self.model(x)

    def backward(self, gradients):
        self.model.zero_grad()
        gradients.backward(retain_graph=True)

    def generate(self, x):
        output = self.forward(x)
        output = output.max(1)[0]
        self.backward(output)
        pooled_gradients = torch.mean(self.gradient, dim=[0, 2, 3])
        activations = self.activation.squeeze(0)
        grad_cam = torch.zeros(activations.shape[1:], dtype=torch.float32)
        for i, weight in enumerate(pooled_gradients):
            grad_cam += weight * activations[i, :, :]
        grad_cam = nn.functional.relu(grad_cam)
        grad_cam /= torch.max(grad_cam)
        return grad_cam.detach().numpy()

# ì´ë¯¸ì§€ ì „ì²˜ë¦¬
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])

def load_model(classes=12):
    # ëª¨ë¸ ì •ì˜ (ResNet50)
    model = models.resnet50(pretrained=True)
    num_ftrs = model.fc.in_features
    model.fc = nn.Linear(num_ftrs, classes)

    # í•™ìŠµëœ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ ë¡œë“œ
    model.load_state_dict(torch.load('model.pth'))
    model.eval()
    return model

def predict_with_gradcam(model, PILimage):
    # ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸°
    image = PILimage.convert('RGB')
    image_tensor = transform(image).unsqueeze(0)

    output = model(image_tensor)
    probs = torch.softmax(output, dim=1)  # í™•ë¥ ë¡œ ë³€í™˜
    probs = probs.squeeze(0).detach().numpy() # í…ì„œë¥¼ ë„˜íŒŒì´ ë°°ì—´ë¡œ ë³€í™˜

    # ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ í´ë˜ìŠ¤ ì¶”ì¶œ
    predicted_label = np.argmax(probs)
    # probs = [int(round(prob)) for prob in probs]

    # Grad-CAM ê³„ì‚°
    grad_cam = GradCAM(model=model, target_layer=model.layer4)
    cam = grad_cam.generate(image_tensor)

    # ì´ë¯¸ì§€ì™€ CAMì„ í•¨ê»˜ ì‹œê°í™”
    img = np.array(PILimage.convert('RGB').resize((224, 224)))
    img = np.float32(img) / 255
    cam = cv2.resize(cam, (224, 224))

    heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)
    heatmap = np.float32(heatmap) / 255
    cam_img = heatmap + np.float32(img)
    cam_img = cam_img / np.max(cam_img)

    cv2.imwrite('tmp/cam.jpg', np.uint8(255 * cam_img))
    return predicted_label, probs

def main():
    with empty1 :
        st.empty()
    with empty2 :
        st.empty()
    with con0:
        st.title("ë‹®ì€ ë™ë¬¼ìƒ ì°¾ê¸° ğŸ¶")

    if ss['upload_file']:
        
        with con0:
            st.subheader("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
            uploaded_file = st.file_uploader(label="", type=["jpg", "jpeg", "png"], key="file_uploader")
        if uploaded_file is not None:
            ss['upload_file'] = False
            ss['process_img'] = True
            ss['image'] = uploaded_file  # backup the file
            st.rerun()
                
    if ss['process_img']:        
        # PIL Imageë¡œ ë³€í™˜
        upload_img = Image.open(ss['image'])
        ss['face_img'] = upload_img
        with con0:
    	    with st_lottie_spinner(lottie_animation, key="download"):             
                model = load_model(12)
                #ë¡œë”© í™”ë©´ í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ì‹œê°„
                time.sleep(2)
                ss['predictions'], ss['probs'] = predict_with_gradcam(model, upload_img)
                # ss['predictions'] = np.random.rand(7)

                ss['grad_cam'] = Image.open('tmp/cam.jpg')
            
                #closet_img, closet_dist = get_closet(face_img)
                ss['closet_img'] = Image.open("asset/testresult2.jpg")
                ss['closet_dist'] = np.random.rand(1)
                
        ss['process_img'] = False
        ss['show_result'] = True
        st.rerun()
            
    if ss['show_result']: 
        result_category = categories[ss['predictions']]
        probability = ss['probs'][ss['predictions']]

        with con1:
            # _, col, _ = st.columns([1, 3, 1])
            # with col:
            st.markdown("<h3>ì›ë³¸ ì‚¬ì§„</h3>", unsafe_allow_html=True)
            st.image(ss['face_img'], width = 350)
                
        with con2:
            st.markdown("<h3>ê°€ì¥ ë¹„ìŠ·í•œ ë™ë¬¼ìƒ</h3>", unsafe_allow_html=True)

            col1, col2 = st.columns(2)
            col1.metric("",result_category)
            col2.metric("", round(probability*100,2))
                        # Inject custom CSS for each progress bar
            for category, prob in zip(categories, ss['probs']):
                prob = int(round(prob*100))

                col5, col6 = st.columns(2)
                with col5:
                    st.write(category)
                with col6:
                    st.progress(prob)
        with con3:
            st.markdown("<h3>Grad-CAM Visualization</h3>", unsafe_allow_html=True)
            image_comparison(
                img2=ss['face_img'],
                img1=ss['grad_cam'],
                width=350,
            )
            
        with con4:
            st.markdown("<h3>ë¹„ìŠ·í•œ ë™ë¬¼ ì‚¬ì§„</h3>", unsafe_allow_html=True)
            image_comparison(
                img2=ss['face_img'],
                img1=ss['closet_img'],
                width=350,
            )

        with con5:
            text = get_category_text(result_category)
            cat_text = f'<h2>{text}</h2>'
            st.markdown(cat_text, unsafe_allow_html=True) 

        with con6:           
            if st.button('ë‹¤ì‹œ ì‹œë„í•˜ê¸°', use_container_width=True, type="primary"):
                ss['process_img'] = False
                ss['show_result'] = False
                ss['upload_file'] = True
                ss.clear()
                st.rerun()
                    
if __name__ == '__main__':
    main()