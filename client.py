import streamlit as st
from streamlit import session_state as ss
from streamlit_lottie import st_lottie_spinner
from streamlit_image_comparison import image_comparison
from st_files_connection import FilesConnection

import numpy as np
import json
import os
import csv

import gdown
import faiss

from PIL import Image
import cv2

import torch
from torch import nn
import torchvision.models as models
import torchvision.transforms as transforms
import s3fs
import warnings

warnings.filterwarnings('ignore')

os.environ['KMP_DUPLICATE_LIB_OK']='True'

import logging

logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger()

#ë ˆì´ì•„ì›ƒ ì„¤ì •
st.set_page_config(
    page_title="ë‹®ì€ ì–¼êµ´ìƒ ì°¾ê¸°",
    page_icon="ğŸ¶",
    layout="wide")

empty1,con0,empty2 = st.columns([0.5,0.5,0.5])
empty1,con1,con2,empty3 = st.columns([0.2,0.5,0.5,0.2])
empyt1,con3,con4,empty3 = st.columns([0.2,0.5,0.5,0.2])
empyt1,con5,empty2 = st.columns([0.2,1.0,0.2])
empyt1,con6,empty2 = st.columns([0.2,1.0,0.2])

conn = st.connection('s3', type=FilesConnection)
fs = s3fs.S3FileSystem(anon=False)

os.makedirs('./temp', exist_ok=True)
# os.makedirs('./faiss', exist_ok=True)

# def download_drive_file(output, url):
    # gdown.download(url, output, quiet=False)

# download_drive_file('faiss', 'https://drive.google.com/file/d/1QSzpvyfEqYM2dbzLPiwVnZdsExP0rMn3/view?usp=sharing')

# print(os.getcwd())
# print(os.listdir('./'))

# file_name = "faiss.zip"
# output_dir = "faiss"
# os.system("unzip "+file_name+" -d "+output_dir)
    
# print(os.getcwd())
# for root, dirs, files in os.walk("./faiss"):
#     path = root.split(os.sep)
#     print((len(path) - 1) * '---', os.path.basename(root))
#     for file in files:
#         print(len(path) * '---', file)
# print('################')
# JSON íŒŒì¼ ê²½ë¡œ
file_path = 'asset/loading.json'
# íŒŒì¼ì„ ì—´ê³  JSON ë°ì´í„° ì½ê¸°
with open(file_path, 'r') as file:
    lottie_animation = json.load(file)

#í™”ë©´ìƒíƒœë¥¼ ì˜ë¯¸í•˜ëŠ” ì„¸ì…˜ ìƒíƒœ
if 'upload_file' not in ss: #íŒŒì¼ ì—…ë¡œë“œ í™”ë©´
    ss['upload_file'] = True

if 'process_img' not in ss:#ì´ë¯¸ì§€ ì²˜ë¦¬ í™”ë©´
    ss['process_img'] = False    

if 'show_result' not in ss:#ê²°ê³¼ ì¶œë ¥ í™”ë©´
    ss['show_result'] = False

#ëª¨ë¸ ë¼ë²¨ ì¹´í…Œê³ ë¦¬.
categories = np.array(['ë¹„ê¸€','ë³´ë”ì½œë¦¬','ì—¬ìš°','í˜¸ë‘ì´','ì‚¬ì','ì¥ëª¨ì¢… ê³ ì–‘ì´','ì¹˜íƒ€','ë‹¨ëª¨ì¢… ê³ ì–‘ì´','ë„ë² ë¥´ë§Œ','ë¦¬íŠ¸ë¦¬ë²„','ëŠ‘ëŒ€','ì‹œì¸„'])

class_map = {'0':'dog','1':'dog','8':'dog','9':'dog','11':'dog',
                '5':'cat','7':'cat','2':'fox','3':'tiger','4':'lion',
                '6':'cheetah','10':'wolf'}
                
animal_text = {
    'ë¹„ê¸€': 'ë°ê³  ì¾Œí™œí•œ ëŠë‚Œ, í° ê·€ì™€ ë§‘ì€ ëˆˆì´ íŠ¹ì§•. í™œë°œí•˜ê³  í˜¸ê¸°ì‹¬ ë§ì€ ì„±ê²©ìœ¼ë¡œ, ì‚¬ëŒë“¤ê³¼ ì‰½ê²Œ ì–´ìš¸ë¦¬ëŠ” ì‚¬ëŒ.',
    'ë³´ë”ì½œë¦¬': 'ì˜ë¦¬í•˜ê³  ì§‘ì¤‘ë ¥ ìˆëŠ” ì¸ìƒ, ë‚ ë µí•œ ëˆˆë§¤ì™€ ë‚ ì¹´ë¡œìš´ ëˆˆë¹›ì´ íŠ¹ì§•. í™œë™ì ì´ë©° ëª©í‘œ ì§€í–¥ì ì¸ ì„±ê²©ì„ ê°€ì§„ ì‚¬ëŒ.',
    'ì—¬ìš°': 'ì˜ë¦¬í•˜ê³  êµí™œí•œ ì´ë¯¸ì§€, ë‚ ì¹´ë¡œìš´ ëˆˆë§¤ì™€ ë¾°ì¡±í•œ ì´ëª©êµ¬ë¹„ê°€ íŠ¹ì§•. ë¯¼ì²©í•˜ê³  ì•¼ë¬´ì§„ ì„±ê²©ì„ ê°€ì§„ ì‚¬ëŒ.',
    'í˜¸ë‘ì´': 'ê°•ë ¬í•˜ê³  ìœ„ì—„ ìˆëŠ” ì¸ìƒ, ë‚ ì¹´ë¡œìš´ ì´ëª©êµ¬ë¹„ê°€ íŠ¹ì§•. ìš©ë§¹í•˜ê³  ê²°ë‹¨ë ¥ ìˆëŠ” ì„±ê²©ì„ ê°€ì§„ ì‚¬ëŒ.',
    'ì‚¬ì': 'ìœ„ì—„ ìˆê³  ê³ ê·€í•œ ëŠë‚Œ, ê°•ë ¬í•œ ëˆˆë¹›ì´ íŠ¹ì§•. ë¦¬ë”ì‹­ê³¼ ìì‹ ê°ì„ ìƒì§•í•˜ëŠ” ì‚¬ëŒ.',
    'ì¥ëª¨ì¢… ê³ ì–‘ì´': 'ìš°ì•„í•˜ê³  ë¶€ë“œëŸ¬ìš´ ì¸ìƒ, í° ëˆˆì´ íŠ¹ì§•. ë…ë¦½ì ì´ê³  ê³ ìƒí•œ ì„±ê²©ì„ ê°€ì§„ ì‚¬ëŒ.',
    'ì¹˜íƒ€': 'ë‚ ë µí•˜ê³  ë¹ ë¥¸ ì´ë¯¸ì§€, ì‘ì€ ì–¼êµ´ì´ íŠ¹ì§•. ë¯¼ì²©í•˜ê³  í™œë™ì ì¸ ì„±ê²©ì„ ê°€ì§„ ì‚¬ëŒ.',
    'ë‹¨ëª¨ì¢… ê³ ì–‘ì´': 'ê¹”ë”í•˜ê³  ë‚ ë µí•œ ì¸ìƒ, ë‚ ì¹´ë¡œìš´ ëˆˆì´ íŠ¹ì§•. ë…ë¦½ì ì´ë©° í˜¸ê¸°ì‹¬ ë§ì€ ì„±ê²©ì„ ê°€ì§„ ì‚¬ëŒ.',
    'ë„ë² ë¥´ë§Œ': 'ê°•ì¸í•˜ê³  ë‚ ì¹´ë¡œìš´ ëŠë‚Œ, ê°•ë ¬í•œ ëˆˆë¹›ì´ íŠ¹ì§•. ìš©ë§¹í•˜ê³  ë³´í˜¸ ë³¸ëŠ¥ì´ ê°•í•œ ì„±ê²©ì„ ê°€ì§„ ì‚¬ëŒ.',
    'ë¦¬íŠ¸ë¦¬ë²„': 'ì¹œê·¼í•˜ê³  ë”°ëœ»í•œ ëŠë‚Œ, ë°ì€ ëˆˆë¹›ì´ íŠ¹ì§•. ì‚¬êµì ì´ê³  ì¶©ì„±ìŠ¤ëŸ¬ìš´ ì„±ê²©ì„ ê°€ì§„ ì‚¬ëŒ.',
    'ëŠ‘ëŒ€': 'ê°•ë ¬í•˜ê³  ì‹ ë¹„ë¡œìš´ ì¸ìƒ, ë‚ ì¹´ë¡œìš´ ì´ëª©êµ¬ë¹„ê°€ íŠ¹ì§•. ììœ ë¡­ê³  ì•¼ì„±ì ì¸ ì„±ê²©ì„ ê°€ì§„ ì‚¬ëŒ.',
    'ì‹œì¸„': 'ê·€ì—½ê³  ì‚¬ë‘ìŠ¤ëŸ¬ìš´ ëŠë‚Œ, ë‘¥ê·¼ ì–¼êµ´ê³¼ í° ëˆˆì´ íŠ¹ì§•. ì• êµ ë§ê³  ì˜¨ìˆœí•œ ì„±ê²©ì„ ê°€ì§„ ì‚¬ëŒ.'
}


st.markdown("""
            <style>
            h2 {
                color: #7340bf;
                justify-content: center;
            }
            </style>
            """, unsafe_allow_html=True
            )

st.markdown("""
            <style>
            h3 {
                color: #7340bf;
                justify-content: center;
            }
            </style>
            """, unsafe_allow_html=True
            )
    
def get_category_text(category):
    return animal_text[category]

# Grad-CAM í´ë˜ìŠ¤ ì •ì˜
class GradCAM:
    def __init__(self, model, target_layer):
        self.model = model
        self.target_layer = target_layer
        self.gradient = None
        self.activation = None
        self.model.eval()
        self.register_hooks()

    def register_hooks(self):
        def backward_hook(module, grad_input, grad_output):
            self.gradient = grad_output[0]

        def forward_hook(module, input, output):
            self.activation = output

        self.target_layer.register_forward_hook(forward_hook)
        self.target_layer.register_backward_hook(backward_hook)

    def forward(self, x):
        return self.model(x)

    def backward(self, gradients):
        self.model.zero_grad()
        gradients.backward(retain_graph=True)

    def generate(self, x):
        output = self.forward(x)
        output = output.max(1)[0]
        self.backward(output)
        pooled_gradients = torch.mean(self.gradient, dim=[0, 2, 3])
        activations = self.activation.squeeze(0)
        grad_cam = torch.zeros(activations.shape[1:], dtype=torch.float32)
        for i, weight in enumerate(pooled_gradients):
            grad_cam += weight * activations[i, :, :]
        grad_cam = nn.functional.relu(grad_cam)
        grad_cam /= torch.max(grad_cam)
        return grad_cam.detach().numpy()

# ì´ë¯¸ì§€ ì „ì²˜ë¦¬
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
    transforms.ToTensor(),  # ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ì •ê·œí™”
])

if torch.cuda.is_available():
    device = 'cuda'
elif torch.backends.mps.is_available():
    device = 'mps'
else:
    device = 'cpu'

def load_model(classes=12):
    # ëª¨ë¸ ì •ì˜ (ResNet50)
    model = models.resnet50(pretrained=True)
    num_ftrs = model.fc.in_features
    model.fc = nn.Linear(num_ftrs, classes)
    
    # í•™ìŠµëœ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ ë¡œë“œ
    model.load_state_dict(torch.load('./model.pth', map_location=device))
    model.eval()
    return model

def load_extractor():
    model = models.resnet50(pretrained=True)  # ì˜ˆì‹œë¡œ ResNet-50 ëª¨ë¸ ì‚¬ìš©
    model.eval()  # í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
    return model

def predict_with_gradcam(model, PILimage):
    # ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸°
    image = PILimage.convert('RGB')
    image_tensor = transform(image).unsqueeze(0)

    output = model(image_tensor)
    probs = torch.softmax(output, dim=1)  # í™•ë¥ ë¡œ ë³€í™˜
    probs = probs.squeeze(0).detach().numpy() # í…ì„œë¥¼ ë„˜íŒŒì´ ë°°ì—´ë¡œ ë³€í™˜

    # ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ í´ë˜ìŠ¤ ì¶”ì¶œ
    predicted_label = np.argmax(probs)
    # probs = [int(round(prob)) for prob in probs]

    # Grad-CAM ê³„ì‚°
    grad_cam = GradCAM(model=model, target_layer=model.layer4)
    cam = grad_cam.generate(image_tensor)

    # ì´ë¯¸ì§€ì™€ CAMì„ í•¨ê»˜ ì‹œê°í™”
    img = np.array(PILimage.convert('RGB').resize((224, 224)))
    img = np.float32(img) / 255
    cam = cv2.resize(cam, (224, 224))

    heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)
    heatmap = np.float32(heatmap) / 255
    cam_img = heatmap + np.float32(img)
    cam_img = cam_img / np.max(cam_img)
    cv2.imwrite('temp/cam.jpg', np.uint8(255 * cam_img))
    return predicted_label, probs

def load_faiss_index(path):
    return faiss.read_index(path)

def image_to_tensor(PILimage):

    image = PILimage.convert('RGB')
    return transform(image).unsqueeze(0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€

def extract_features(model, image_tensor):
    with torch.no_grad():
        features = model(image_tensor)
    return features.numpy().flatten()  # ë²¡í„°ë¡œ ë³€í™˜

def search_similar_images(index, query_vector, k=1):
    distances, indices = index.search(np.array([query_vector]), k)
    return distances, indices

def get_all_image_paths(root_folder):
    image_paths = []
    for dirpath, _, filenames in os.walk(root_folder):
        for filename in filenames:
            if filename.lower().endswith(('.png', '.jpg', '.jpeg')):
                image_paths.append(os.path.join(dirpath, filename))
    return image_paths

def rerun_app():
    ss['process_img'] = False
    ss['show_result'] = False
    ss['upload_file'] = True
    ss.clear()
    st.rerun()
    # st.experimental_rerun()

def main():
    with empty1 :
        st.empty()
    with empty2 :
        st.empty()
    with con0:
        st.markdown("<h1 style='text-align: center;'>ë‹®ì€ ë™ë¬¼ìƒ ì°¾ê¸° ğŸ¶</h1>", unsafe_allow_html=True)
        

    if ss['upload_file']:
        
        with con0:
            st.subheader("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
            uploaded_file = st.file_uploader(label=" ", type=["jpg", "jpeg", "png"], key="file_uploader")
        if uploaded_file is not None:
            ss['upload_file'] = False
            ss['process_img'] = True
            ss['image'] = uploaded_file  # backup the file
            st.rerun()
    if ss['process_img']:        
        # PIL Imageë¡œ ë³€í™˜
        upload_img = Image.open(ss['image'])
        upload_img_gray = upload_img.convert('L')
        logger.debug("Image loaded successfully.")
        logger.debug(f"Image size: {upload_img.size}")
        logger.debug(f"Image size: {upload_img_gray.size}")

        ss['face_img'] = upload_img
        with con0:
            with st_lottie_spinner(lottie_animation, key="download"):     
                model = load_model(12)

                ss['predictions'], ss['probs'] = predict_with_gradcam(model, upload_img_gray)
                
                cv2.imwrite('temp/cam.jpg', cv2.resize(cv2.imread('temp/cam.jpg'), upload_img.size))
                ss['grad_cam'] = Image.open('temp/cam.jpg')
                
                extractor = load_extractor()
                
                lcategory = class_map[str(ss['predictions'])]
                loaded_index = load_faiss_index(f'faiss/faiss_{lcategory}.index')
                logger.debug("faiss loaded.")
                query_image_tensor = image_to_tensor(upload_img)
                query_vector = extract_features(extractor, query_image_tensor)
                logger.debug("features extracted")
                distances, indices = search_similar_images(loaded_index, query_vector, k=5)
                logger.debug("similar images searched")
                df = conn.read(f"dl2024-bucket/list/{lcategory}_list.csv", input_format="csv", ttl=600)
                image_files = df.iloc[:, 0].tolist()
                for idx, distance in zip(indices[0], distances[0]):
                    if image_files[idx].split('/')[2] == lcategory:
                        # ss['closest_img'] = Image.open(image_files[idx])
                        ss['closest_img'] = Image.open(fs.open(f'dl2024-bucket{image_files[idx]}', mode='rb').read())
                        ss['closest_dist'] = distance
                        break
                             
    if ss['show_result']: 
        result_category = categories[ss['predictions']]
        probability = ss['probs'][ss['predictions']]

        with con1:
            # _, col, _ = st.columns([1, 3, 1])
            # with col:
            st.markdown("<h3 style='text-align: center;'>ì›ë³¸ ì‚¬ì§„</h3>", unsafe_allow_html=True)
            # st.image(ss['face_img'], use_column_width='auto')
            st.image(ss['face_img'], width=500)
                
        with con2:
            st.markdown("<h3 style='text-align: center;'>ê°€ì¥ ë¹„ìŠ·í•œ ë™ë¬¼ìƒ</h3>", unsafe_allow_html=True)

            col1, col2 = st.columns(2)
            col1.metric("",result_category)
            col2.metric("", round(probability*100,2))
                        # Inject custom CSS for each progress bar

            sorted_indices = np.argsort(ss['probs'])[::-1]
            ss['probs'] = ss['probs'][sorted_indices]
            sorted_categories = categories[sorted_indices]

            top_k = 0
            for category, prob in zip(sorted_categories, ss['probs']):
                prob = int(round(prob*100))

                col5, col6 = st.columns(2)
                with col5:
                    st.write(category)
                with col6:
                    st.progress(prob)
                top_k += 1
                if top_k == 10:
                    break
        with con3:
            st.markdown("<h3 style='text-align: center;'>Grad-CAM Visualization</h3>", unsafe_allow_html=True)
            image_comparison(
                img2=ss['face_img'],
                img1=ss['grad_cam'],
                width=500,
            )
            
        with con4:
            st.markdown("<h3 style='text-align: center;'>ë¹„ìŠ·í•œ ë™ë¬¼ ì‚¬ì§„</h3>", unsafe_allow_html=True)
            image_comparison(
                img2=ss['face_img'],
                img1=ss['closest_img'],
                width=500,
            )

        with con5:
            text = get_category_text(result_category)
            cat_text = f'<h2 style="text-align: center;">{text}</h2>'
            st.markdown(cat_text, unsafe_allow_html=True) 

        with con6:           
            st.markdown(
                """
            <style>
            button {
                height: 60px;
                font-weight: bold;
                font-style: italic
                font-size: 54px; !important
            }
            </style>
            """,
                unsafe_allow_html=True,
            )
            rerun_text = 'ë‹¤ì‹œ ì‹œë„í•˜ê¸°'
            if st.button(rerun_text, use_container_width=True, type="primary"):
                rerun_app()
                    
if __name__ == '__main__':
    main()